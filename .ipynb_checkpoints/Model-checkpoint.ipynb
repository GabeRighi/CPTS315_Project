{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bf4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch_directml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1be7a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the Price of 70801/79011 cards\n",
      "Loaded data of 60987/84235 cards\n"
     ]
    }
   ],
   "source": [
    "def loadPrices(pricePath):\n",
    "    with open(pricePath, \"r\") as priceFile:\n",
    "        uuidToPrice = {}\n",
    "        prices = json.load(priceFile)\n",
    "        prices = prices['data']\n",
    "        nonfoils = set() #Debug Sets\n",
    "        foils = set()\n",
    "        nones = set()\n",
    "        for i in prices:\n",
    "            if 'paper' in prices[i]:\n",
    "                for vendor in prices[i]['paper']:\n",
    "                    priced = False\n",
    "                    for sellType in ['retail', 'buylist']:\n",
    "                        if sellType in prices[i]['paper'][vendor]:\n",
    "                            if 'normal' in prices[i]['paper'][vendor][sellType]:\n",
    "                                uuidToPrice[i] = list(prices[i]['paper'][vendor][sellType]['normal'].values())[-1]\n",
    "                                nonfoils.add(i)\n",
    "                                priced = True\n",
    "                                break\n",
    "                            elif 'foil' in prices[i]['paper'][vendor][sellType]:\n",
    "                                uuidToPrice[i] = list(prices[i]['paper'][vendor][sellType]['foil'].values())[-1]\n",
    "                                foils.add(i)\n",
    "                                priced = True\n",
    "                                break\n",
    "                            else:\n",
    "                                print(f\"No foil or nonfoil {i}\")\n",
    "                    if not priced:\n",
    "                        nones.add(i)\n",
    "        print(f\"Loaded the Price of {len(uuidToPrice)}/{len(prices)} cards\")\n",
    "        return uuidToPrice\n",
    "\n",
    "def loadCards(priceDict, cardPath):\n",
    "    with open(cardPath, \"r\") as cardFile:\n",
    "        uuidToCardData = {}\n",
    "        data = json.load(cardFile)\n",
    "        data = data['data']\n",
    "        priceMisses = set()\n",
    "        for i in data:\n",
    "            if data[i]['language'] == 'English' and 'legalities' in data[i] and 'MOM' not in data[i]['printings'] and i in priceDict and len(data[i]['legalities']) != 0:\n",
    "                uuidToCardData[i] = data[i]\n",
    "            if i not in priceDict:\n",
    "                priceMisses.add(i)\n",
    "        print(f\"Loaded data of {len(uuidToCardData)}/{len(data)} cards\")\n",
    "        return uuidToCardData\n",
    "\n",
    "mtgCardsPath = \"./AllIdentifiers.json\"\n",
    "mtgPricesPath = \"./AllPrices.json\"\n",
    "uuidToPrice = loadPrices(mtgPricesPath)\n",
    "uuidToCard = loadCards(uuidToPrice,mtgCardsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f195a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHot(allClasses, classSubset):\n",
    "    oneHot = [0] * len(allClasses)\n",
    "    for c in classSubset:\n",
    "        try:\n",
    "            oneHot[allClasses.index(c)] = 1\n",
    "        except:\n",
    "            pass\n",
    "    return oneHot\n",
    "\n",
    "def prepareData(idToCard):\n",
    "    # Supertype, subtype, legalities, keywords, artists (left to right 0 indexed)\n",
    "    classCount = 8\n",
    "    onehots = [set() for _ in range(classCount)]\n",
    "    keywords = {}\n",
    "    for uuid in idToCard:\n",
    "        entry = idToCard[uuid]\n",
    "        for t in entry.get('supertypes', []):\n",
    "            onehots[enum['supertype']].add(t)\n",
    "        for t in entry.get('subtypes', []):\n",
    "            onehots[enum['subtype']].add(t)\n",
    "        for l in entry.get('legalities', []):\n",
    "            onehots[enum['legalities']].add(l)\n",
    "        for k in entry.get('keywords', []):\n",
    "            keywords[k] = keywords.get(k,0)\n",
    "            keywords[k] += 1\n",
    "            if keywords[k] > 1:\n",
    "                onehots[enum['keywords']].add(k)\n",
    "        if entry.get('artist'):\n",
    "            onehots[enum['artist']].add(entry['artist'])\n",
    "        for l in entry.get('printings', []):\n",
    "            onehots[enum['printings']].add(l)\n",
    "        for r in entry.get('rarity', None):\n",
    "            if r is not None:\n",
    "                onehots[enum['rarity']].add(r)\n",
    "        for t in entry.get('flavorText',\"\"):\n",
    "            for word in t:\n",
    "                onehots[enum['flavorText']].add(word)\n",
    "\n",
    "    for s in onehots:\n",
    "        globalOneHots.append(sorted(list(s)))\n",
    "    \n",
    "    globalOneHots.append(sorted(['X','U','B','R','G','W','C','P','S']))\n",
    "    \n",
    "                         \n",
    "        \n",
    "        \n",
    "class CustomMTGDataset(Dataset):\n",
    "    def __init__(self,uuidList):\n",
    "        self.uuidList = uuidList\n",
    "        self.ac = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.uuidList)\n",
    "    #PROPOSED FEATURE VECTOR V 1\n",
    "    # CMC (NUMBER)\n",
    "    # NUMBER OF PIPS (ONE HOT BUT NOT ONE)\n",
    "    # COLORS (ONE HOT)\n",
    "    # PRINTINGS (NUMBER)\n",
    "    # PRINTINGS (ONE HOT)\n",
    "    # SUBTYPE (ONE HOT)\n",
    "    # SUPERTYPE (ONE HOT)\n",
    "    # LEGALITIES (ONE HOT)\n",
    "    # KEYWORDS (ONE HOT)\n",
    "    # ARTIST (ONE HOT) ?\n",
    "    # RARITY (ONE HOT)\n",
    "    # FLAVOR TEXT (ONE HOT)\n",
    "    # POWER (NUMBER)\n",
    "    # TOUGHNESS (NUMBER)\n",
    "    # LOYALTY (NUMBER)\n",
    "    # FLAVOR TEXT LENGTH (NUMBER)\n",
    "    # FLAVOR TEXT (ONE HOT)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         self.ac += 1\n",
    "#         print(self.ac)\n",
    "        uuid = self.uuidList[idx]\n",
    "        cardData = uuidToCard[uuid]\n",
    "        featureVector = []\n",
    "        phrexian = 0\n",
    "        # Add 1, so that CMC of 0 is not ignored\n",
    "        if 'convertedManaCost' in cardData:\n",
    "            featureVector.append(int(cardData['convertedManaCost']) + 1)\n",
    "        else:\n",
    "            featureVector.append(0)\n",
    "                         \n",
    "        oneHotMana = [0] * len(globalOneHots[enum['pips']])\n",
    "        colors = [0] * len(globalOneHots[enum['pips']])   \n",
    "        if 'manaCost' in cardData:\n",
    "            cost = cardData['manaCost']\n",
    "            i = 0\n",
    "            while(i < len(cost)):\n",
    "                if(cost[i] == '/'):\n",
    "                    cost = cost[:i] + \"}{\" + cost[i+1:]\n",
    "                i += 1\n",
    "            cost = cost.split(\"}\")\n",
    "            for i in range(len(cost)):\n",
    "                cost[i] = cost[i].strip(\"{\")\n",
    "                if cost[i].isdigit() or cost[i] == '':\n",
    "                    continue\n",
    "                oneHotMana[globalOneHots[enum['pips']].index(cost[i])] += 1\n",
    "                colors[globalOneHots[enum['pips']].index(cost[i])] = 1                     \n",
    "        else:\n",
    "            for i in cardData['colors']:\n",
    "                colors[globalOneHots[enum['pips']].index(i)] = 1\n",
    "            \n",
    "        featureVector.extend(oneHotMana)\n",
    "        featureVector.extend(colors)\n",
    "        \n",
    "        featureVector.append(len(cardData.get('printings',[])))\n",
    "        \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['printings']], cardData.get('printings',[])))\n",
    "        \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['subtype']], cardData.get('subtype',[])))\n",
    "                                                      \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['supertype']], cardData.get('supertype',[])))\n",
    "        \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['legalities']], cardData.get('legalities',[])))\n",
    "                             \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['keywords']], cardData.get('keywords',[])))\n",
    "                             \n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['artist']], [cardData.get('artist')]))\n",
    "\n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['rarity']], [cardData.get('rarity')]))\n",
    "\n",
    "        featureVector.extend(getOneHot(globalOneHots[enum['flavorText']], cardData.get('flavorText', \"\")))\n",
    "\n",
    "        featureVector.append(len(cardData.get(\"flavorText\", \"\")))\n",
    "\n",
    "                             \n",
    "        cardPower = cardData.get('power', \"0\")\n",
    "        if cardPower.isdigit():\n",
    "            featureVector.append(int(cardPower))\n",
    "            featureVector.append(0)\n",
    "        else:\n",
    "            featureVector.append(0)\n",
    "            featureVector.append(1)\n",
    "        \n",
    "        \n",
    "        cardToughness = cardData.get('toughness', \"0\")\n",
    "        if cardToughness.isdigit():\n",
    "            featureVector.append(int(cardToughness))\n",
    "            featureVector.append(0)\n",
    "        else:\n",
    "            featureVector.append(0)\n",
    "            featureVector.append(1)\n",
    "        \n",
    "        cardLoyalty = cardData.get('loyalty', \"0\")\n",
    "        if cardLoyalty.isdigit():\n",
    "            featureVector.append(int(cardLoyalty))\n",
    "            featureVector.append(0)\n",
    "        else:\n",
    "            featureVector.append(0)\n",
    "            featureVector.append(1)\n",
    "        \n",
    "        label = torch.tensor(float(uuidToPrice[uuid]))\n",
    "        return np.array(featureVector, dtype=\"float32\"), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c2f0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "enum = {'supertype' : 0, 'subtype' : 1, 'legalities' : 2, 'keywords' : 3, 'artist' : 4,'printings' : 5,'rarity' : 6,'flavorText':7,'pips' : 8  }\n",
    "\n",
    "globalOneHots = []\n",
    "prepareData(uuidToCard)\n",
    "allCards = list(uuidToCard.keys())\n",
    "trainingDataPercent = 0.8\n",
    "trainingIndex = int(len(allCards) * trainingDataPercent)\n",
    "random.shuffle(allCards)\n",
    "\n",
    "num_epochs = 10         # the number of epochs (each epoch: scanning the entire training set)\n",
    "batch_size = 32        # how many samples are used in each iteration of SGD/Adam update\n",
    "learning_rate = 0.01   # learning rate or step size used in gradient-based optimization algorithm\n",
    "\n",
    "train_dataset = CustomMTGDataset(uuidList=allCards[:trainingIndex])\n",
    "\n",
    "test_dataset = CustomMTGDataset(uuidList=allCards[trainingIndex:])\n",
    "\n",
    "input_size = len(train_dataset.__getitem__(0)[0])       \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7831f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,1) \n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.fc2 = nn.Linear(hidden_size, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        # out = self.relu(out)\n",
    "        # out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19b6bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1525/1525], Loss: 126.6296\n",
      "Accuracy of the network on the 12224 test cards: 0.0\n",
      "Accuracy of the network on the training cards: 0.0\n",
      "Epoch [2/10], Step [1525/1525], Loss: 2024.2830\n",
      "Accuracy of the network on the 12224 test cards: 0.0\n",
      "Accuracy of the network on the training cards: 0.0\n",
      "Epoch [3/10], Step [1525/1525], Loss: 1343.4006\n",
      "Accuracy of the network on the 12224 test cards: 0.0\n",
      "Accuracy of the network on the training cards: 0.0\n",
      "Epoch [4/10], Step [1525/1525], Loss: 826.2759\n",
      "Accuracy of the network on the 12224 test cards: 0.0\n",
      "Accuracy of the network on the training cards: 0.0\n",
      "Epoch [5/10], Step [1525/1525], Loss: 280.1086\n",
      "Accuracy of the network on the 12224 test cards: 0.0\n",
      "Accuracy of the network on the training cards: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m test_acc_list, train_acc_list \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mfor\u001b[39;00m i, (cards, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader): \n\u001b[1;32m     14\u001b[0m \u001b[39m#         print(len(card))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#         print(len(label))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         outputs \u001b[39m=\u001b[39m model(cards)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     17\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[34], line 156\u001b[0m, in \u001b[0;36mCustomMTGDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    153\u001b[0m     featureVector\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m)\n\u001b[1;32m    155\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mfloat\u001b[39m(uuidToPrice[uuid]))\n\u001b[0;32m--> 156\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(featureVector, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m\"\u001b[39;49m), label\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# device = torch_directml.device()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNet(input_size).to(device)\n",
    "# outputs = model(card)\n",
    "threshold = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "# Train the model\n",
    "train_acc_list, test_acc_list = [],[]\n",
    "total_step = len(train_loader)\n",
    "test_acc_list, train_acc_list = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (cards, labels) in enumerate(train_loader): \n",
    "#         print(len(card))\n",
    "#         print(len(label))\n",
    "        outputs = model(cards).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(i)\n",
    "        if i == len(train_loader) - 1:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "#     # Test the model and plot training/testing accuracy\n",
    "#     # In test phase, we don't need to compute gradients \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for cards, labels in test_loader:\n",
    "            outputs = model(cards).squeeze()\n",
    "            total += labels.size(0)\n",
    "            # correct += ((torch.abs(outputs - labels) / labels) <= threshold).sum().item()\n",
    "            correct += (outputs == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the {len(test_loader)*batch_size} test cards: {100 * correct / total}')\n",
    "        test_acc_list.append(100 * correct / total)\n",
    "\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for cards, labels in train_loader:\n",
    "            outputs = model(cards).squeeze()\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs == labels).sum().item()\n",
    "            # correct += ((torch.abs(outputs - labels) / labels) <= threshold).sum().item()\n",
    "\n",
    "        print(f'Accuracy of the network on the training cards: {100 * correct / total}')\n",
    "        train_acc_list.append(100 * correct / total)\n",
    "            \n",
    "plt.plot(train_acc_list, '-b', label='train acc')\n",
    "plt.plot(test_acc_list, '-r', label='test acc')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(rotation=60)\n",
    "plt.title('Accuracy ~ Epoch')\n",
    "# plt.savefig('assets/accr_{}.png'.format(cfg_idx))\n",
    "plt.show()\n",
    "        \n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd805b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15.3842,  8.1965, 20.9031, -2.8924, 26.1725, -5.6162,  2.7592, 16.9796,\n",
      "         3.7551,  4.7570, 11.4061, 14.6072,  9.4225, -0.0779,  1.4492, -1.4857,\n",
      "         0.3010, -2.3707, 14.5184, -1.4795, -6.2071,  7.5816,  2.3611,  2.5048,\n",
      "        10.6082, -1.7251, 26.1534, -5.2075, 20.6655, 14.8271,  6.6707, 18.4417])\n",
      "torch.float32\n",
      "torch.float32\n",
      "tensor([ 0.4600,  0.7000, 25.0600,  0.4200, 19.8200,  0.2700,  2.6000,  0.4400,\n",
      "         0.2800,  0.2300,  4.3900,  0.2800,  0.7500,  0.1500,  0.2900,  0.2300,\n",
      "        10.2200,  0.1400,  1.6900,  0.6400,  0.1500,  4.4700,  0.0600,  0.3500,\n",
      "        27.5900,  0.3700,  2.9200,  0.2400,  2.6400,  0.3900,  0.3300,  0.2800])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(labels\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(labels)\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (outputs \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy of the network on the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(test_loader)\u001b[39m*\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m test cards: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mcorrect\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mtotal\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for cards, labels in test_loader:\n",
    "        outputs = model(cards).squeeze()\n",
    "        total += labels.size(0)\n",
    "        # correct += ((torch.abs(outputs - labels) / labels) <= threshold).sum().item()\n",
    "        print(outputs)\n",
    "        print(outputs.dtype)\n",
    "        print(labels.dtype)\n",
    "        print(labels)\n",
    "        raise\n",
    "        correct += (outputs == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the {len(test_loader)*batch_size} test cards: {100 * correct / total}')\n",
    "    test_acc_list.append(100 * correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
